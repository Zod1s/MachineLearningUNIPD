{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fundamentals of Information Systems\n",
    "\n",
    "## Python Programming (for Data Science)\n",
    "\n",
    "### Master's Degree in Data Science\n",
    "\n",
    "#### Giorgio Maria Di Nunzio\n",
    "#### (Courtesy of Gabriele Tolomei FIS 2018-2019)\n",
    "<a href=\"mailto:giorgiomaria.dinunzio@unipd.it\">giorgiomaria.dinunzio@unipd.it</a><br/>\n",
    "University of Padua, Italy<br/>\n",
    "2021/2022<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 9: Data Preparation with <code>pandas</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Does Data Preparation Mean?\n",
    "\n",
    "-  It typically consists of **loading**, **cleaning**, **transforming**, and **rearranging** data (the last three steps are also referred to as data **\"munging\"**). \n",
    "\n",
    "-  Such tasks are often reported to take up 80% or more of your development time (for a machine learning/data science task). \n",
    "\n",
    "-  Sometimes it can be achieved by using a mixture of tools, i.e., from general-purpose programming languages, like Python, Perl, R, or Java, to UNIX tools like <code>**sed**</code> or <code>**awk**</code>.\n",
    "\n",
    "-  Luckily, <code>**pandas**</code> provides you with a single, high-level, flexible, and fast set of tools to enable you to manipulate data into the right form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Our Focus\n",
    "\n",
    "1.  Handling missing data (**NA** or **N**ot **A**vailable)\n",
    "\n",
    "2.  Dealing with duplicates\n",
    "\n",
    "3.  Managing very extreme values (i.e., **outliers**)\n",
    "\n",
    "4.  Combining multiple datasets into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender  occupation zip_code\n",
      "user_id                                 \n",
      "1         24      M  technician    85711\n",
      "2         53      F       other    94043\n",
      "3         23      M      writer    32067\n",
      "4         24      M  technician    43537\n",
      "5         33      F       other    15213\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Before we start our journey on data preparation with pandas,\n",
    "we get back to the example we used in Lecture 08.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n",
    "# The first line of the file represents the header, and each field\n",
    "# is separated by a pipe\n",
    "\"\"\"\n",
    "We specify the url where the data is located, the character u|sed to separate fields ('|')\n",
    "and the name of the column to use as row label (otherwise, RangeInteger will be used)\n",
    "\"\"\"\n",
    "users = pd.read_csv(url, sep='|', index_col='user_id')\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling Missing Data (*NA*)\n",
    "\n",
    "-  Missing data (**NA**) may either be data that does not exist or that exists but was not observed (e.g., due to measurement issues).\n",
    "\n",
    "-  <code>**pandas**</code> makes working with missing data as painless as possible. For example, all of the descriptive statistics on <code>**pandas**</code> objects exclude **NA** by default.\n",
    "\n",
    "-  <code>**pandas**</code> represents **NA** using so-called **sentinel values**.\n",
    "\n",
    "-  Two of the most common sentinel values are <code>**None**</code> and the floating point value <code>**NaN**</code> (**N**ot **a** **N**umber)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the boolean DataFrame: (943, 4)\n",
      "\n",
      "           age  gender  occupation  zip_code\n",
      "user_id                                     \n",
      "1        False   False       False     False\n",
      "2        False   False       False     False\n",
      "3        False   False       False     False\n",
      "4        False   False       False     False\n",
      "5        False   False       False     False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's see if there are any missing data (NA) on our loaded dataset.\n",
    "\"\"\"\n",
    "\n",
    "# isnull() returns a boolean DataFrame with the same shape of the DataFrame object\n",
    "# where you invoke the method. Each entry of this new boolean DataFrame either contains\n",
    "# True or False depending on whether the corresponding entry in the original DataFrame\n",
    "# is missing or not\n",
    "print(\"Shape of the boolean DataFrame: {}\\n\".format(users.isnull().shape))\n",
    "print(users.isnull().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the boolean Series: (4,)\n",
      "\n",
      "age           False\n",
      "gender        False\n",
      "occupation    False\n",
      "zip_code      False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In order to see which column has at least one missing value,\n",
    "we can call the method any() on the boolean DataFrame above.\n",
    "This returns a boolean Series which contains an entry for each column \n",
    "(row aggregation) which evaluates to True if at least one element\n",
    "of that column is True, False otherwise.\n",
    "\"\"\"\n",
    "print(\"Shape of the boolean Series: {}\\n\".format(users.isnull().any().shape))\n",
    "print(users.isnull().any().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the boolean Series: (943,)\n",
      "\n",
      "user_id\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We have verified that our dataset does not contain any missing value.\n",
    "What if, though, I would like to obtain a row-wise (i.e., column aggregation)\n",
    "boolean Series containing a value for each row, which tells me whether that\n",
    "row contains or not at least one NA value?\n",
    "\"\"\"\n",
    "\n",
    "print(\"Shape of the boolean Series: {}\\n\".format(users.isnull().any(axis=1).shape))\n",
    "print(users.isnull().any(axis=1).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Is there at least a missing value in our DataFrame? A: False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In order to find whether there exists at least one NA on the whole DataFrame\n",
    "we can simply aggregate one more time the boolean Series above using another any()\n",
    "\"\"\"\n",
    "\n",
    "print(\"Q: Is there at least a missing value in our DataFrame? A: {}\".\n",
    "      format(users.isnull().any().any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Is there at least a missing value in our DataFrame? A: False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Of course, the same thing can be achieved using different approaches.\n",
    "This is possibly the quickest solution.\n",
    "\"\"\"\n",
    "\n",
    "# values returns a 2-D numpy array (ndarray) and any() \"flatten\" it \n",
    "print(\"Q: Is there at least a missing value in our DataFrame? A: {}\".\n",
    "      format(users.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 missing values (NA) in the DataFrame\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This solution makes exactly the same 3 steps as above but instead of computing\n",
    "boolean aggregation from the boolean DataFrame, it sum boolean values over the rows\n",
    "(i.e., column-wise) and finally makes a final aggregation step (sum) to obtain\n",
    "the number of missing values of the DataFrame.\n",
    "NOTE: this is generally slower but it provides you with an extra information\n",
    "(i.e., how many NA values are in the DataFrame, not just a boolean value!)\n",
    "\"\"\"\n",
    "print(\"There are {} missing values (NA) in the DataFrame\".\n",
    "      format(users.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose we want to randomly perturbate our dataset with some missing values.\n",
    "First of all, let's create a deep copy of our original DataFrame.\n",
    "\"\"\"\n",
    "\n",
    "# Prepare the deep copy of the DataFrame where we are going to randomly insert\n",
    "# some missing values (NA)\n",
    "users_with_na = users.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random row indices: [103 436 861 271 107  72 701  21 615 122]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's create a uniform random sample of size=10 drawn from the range [1, 943]\n",
    "\"\"\"\n",
    "np.random.seed(42)\n",
    "row_indices = np.random.randint(low = 1, high = 944, size = 10)\n",
    "# alternatively, use np.random.choice(np.arange(1, 944), size=10, replacement=False)\n",
    "print(\"Random row indices: {}\".format(row_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWe are going to use the first half of the randomly selected indices\\nfor populating with np.NaN the column 'age', whilst the second half\\nis going to be used to set to None the column 'occupation'.\\nThe two middle indices will be used for both. \\nIn other words:\\n- rows labeled as 103, 436, 861, 271 will be used to\\nset column 'age' to np.NaN\\n- rows labeled as 701, 21, 615, 122 will be used to\\nset column 'occupation' as None\\n- rows labeled as 107 and 72 will be used to set both\\ncolumn 'age' to np.NaN and column 'occupation' to None\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We are going to use the first half of the randomly selected indices\n",
    "for populating with np.NaN the column 'age', whilst the second half\n",
    "is going to be used to set to None the column 'occupation'.\n",
    "The two middle indices will be used for both. \n",
    "In other words:\n",
    "- rows labeled as 103, 436, 861, 271 will be used to\n",
    "set column 'age' to np.NaN\n",
    "- rows labeled as 701, 21, 615, 122 will be used to\n",
    "set column 'occupation' as None\n",
    "- rows labeled as 107 and 72 will be used to set both\n",
    "column 'age' to np.NaN and column 'occupation' to None\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's first extract the records we want to update for column 'age':\n",
      "user_id\n",
      "103    26\n",
      "436    30\n",
      "861    38\n",
      "271    51\n",
      "107    39\n",
      "72     48\n",
      "Name: age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's first extract the records we want to update for column 'age':\\n{}\".\n",
    "      format(users_with_na.loc[row_indices[:6], 'age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's now extract the records we want to update for column 'occupation':\n",
      "user_id\n",
      "107        scientist\n",
      "72     administrator\n",
      "701        librarian\n",
      "21            writer\n",
      "615         educator\n",
      "122           writer\n",
      "Name: occupation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's now extract the records we want to update for column 'occupation':\\n{}\".\n",
    "      format(users_with_na.loc[row_indices[4:], 'occupation']))\n",
    "# I swear, I didn't do it on purpose! \n",
    "# This was truly the outcome of a purely (pseudo-)random experiment but apparently\n",
    "# 'scientist' will be sacrificed and set to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's set the values as we planned.\n",
    "\"\"\"\n",
    "users_with_na.loc[row_indices[:6], 'age'] = np.nan\n",
    "users_with_na.loc[row_indices[4:], 'occupation'] = None\n",
    "# NOTE: the same won't work if we use something like the following:\n",
    "# users_with_na.loc[row_indices[:6]]['age'] = np.nan\n",
    "# users_with_na.loc[row_indices[4:]]['occupation'] = None\n",
    "# This is because in case of [] operator, we are actually \n",
    "# accessing a copy of the selected slice, whereas above we are working on a view.\n",
    "# More information on this - a.k.a. SettingWithCopyWarning - is available here: \n",
    "# https://www.dataquest.io/blog/settingwithcopywarning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's see how column 'age' looks like:\n",
      "user_id\n",
      "103     NaN\n",
      "436     NaN\n",
      "861     NaN\n",
      "271     NaN\n",
      "107     NaN\n",
      "72      NaN\n",
      "701    51.0\n",
      "Name: age, dtype: float64\n",
      "\n",
      "Let's see how column 'occupation' looks like:\n",
      "user_id\n",
      "271    engineer\n",
      "107        None\n",
      "72         None\n",
      "701        None\n",
      "21         None\n",
      "615        None\n",
      "122        None\n",
      "Name: occupation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's verify if changes actually took place!\n",
    "\"\"\"\n",
    "print(\"Let's see how column 'age' looks like:\\n{}\".\n",
    "      format(users_with_na.loc[row_indices[:7], 'age']))\n",
    "print()\n",
    "print(\"Let's see how column 'occupation' looks like:\\n{}\".\n",
    "      format(users_with_na.loc[row_indices[3:], 'occupation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Is there at least a missing value in our DataFrame? A: True\n",
      "\n",
      "There are 12 missing values (NA) in the DataFrame\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now, let's try to see if the tests above we run for finding any NA work correctly.\n",
    "\"\"\"\n",
    "print(\"Q: Is there at least a missing value in our DataFrame? A: {}\".\n",
    "      format(users_with_na.isnull().any().any()))\n",
    "print()\n",
    "print(\"There are {} missing values (NA) in the DataFrame\".\n",
    "      format(users_with_na.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Filtering Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the original DataFrame = 943\n",
      "\n",
      "Number of records in the cleaned DataFrame = 933\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "You may want to drop rows or columns of a DataFrame which are all NA \n",
    "or only those containing any NAs. \n",
    "The pandas.dropna function by default drops any row containing a missing value.\n",
    "By default, dropna returns a new object but we can specify inplace=True for\n",
    "any in-place change.\n",
    "\"\"\"\n",
    "\n",
    "# This will drop all the rows containing at least one NA\n",
    "cleaned_users = users_with_na.dropna()\n",
    "\n",
    "# After issuing the above command, we are expecting the DataFrame to have 10 rows less\n",
    "# (i.e., 933 instead of 943)\n",
    "print(\"Number of records in the original DataFrame = {}\\n\".format(users_with_na.shape[0]))\n",
    "print(\"Number of records in the cleaned DataFrame = {}\".format(cleaned_users.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the original DataFrame = 943\n",
      "\n",
      "Number of records in the cleaned DataFrame = 943\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "If we instead want to delete only those rows which are FULL of NAs,\n",
    "then we have to pass how='all' to dropna.\n",
    "\"\"\"\n",
    "# This will drop all the rows containing ALL NAs\n",
    "cleaned_users_all = users_with_na.dropna(how = 'all')\n",
    "\n",
    "# After issuing the above command, how many rows will be dropped?\n",
    "print(\"Number of records in the original DataFrame = {}\\n\".format(users_with_na.shape[0]))\n",
    "print(\"Number of records in the cleaned DataFrame = {}\".format(cleaned_users_all.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "As usual, dropna works on rows (axis 0) by default.\n",
    "Instead, if we want to delete columns corresponding to a missing value\n",
    "we can pass axis=1 argument to dropna.\n",
    "\"\"\"\n",
    "# This will drop all the columns containing at least one NA\n",
    "cleaned_users_columns = users_with_na.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# How many columns are we expecting the above command will drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in the original DataFrame = 4\n",
      "\n",
      "Number of columns in the cleaned DataFrame = 2\n"
     ]
    }
   ],
   "source": [
    "# After issuing the above command, weare expecting the DataFrame to have 2 columns less\n",
    "# (i.e., 2 instead of 4, as 'age' and 'occupation' have both at least one NA value)\n",
    "print(\"Number of columns in the original DataFrame = {}\\n\".format(users_with_na.shape[1]))\n",
    "print(\"Number of columns in the cleaned DataFrame = {}\".format(cleaned_users_columns.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Filling in Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's see how column 'age' looks like:\n",
      "user_id\n",
      "103    0.0\n",
      "436    0.0\n",
      "861    0.0\n",
      "271    0.0\n",
      "107    0.0\n",
      "72     0.0\n",
      "Name: age, dtype: float64\n",
      "\n",
      "Let's see how column 'occupation' looks like:\n",
      "user_id\n",
      "107    0\n",
      "72     0\n",
      "701    0\n",
      "21     0\n",
      "615    0\n",
      "122    0\n",
      "Name: occupation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "'fillna' fill in missing data with some values, rather than filtering them out.\n",
    "\"\"\"\n",
    "# Suppose we fill all missing values with 0 (not in-place, otherwise set inplace=True)\n",
    "users_fill_na = users_with_na.fillna(0)\n",
    "\n",
    "# Let's verify if changes actually took place!\n",
    "print(\"Let's see how column 'age' looks like:\\n{}\".\n",
    "      format(users_fill_na.loc[row_indices[:6], 'age']))\n",
    "print()\n",
    "print(\"Let's see how column 'occupation' looks like:\\n{}\".\n",
    "      format(users_fill_na.loc[row_indices[4:], 'occupation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's see how column 'age' looks like:\n",
      "user_id\n",
      "103    0.0\n",
      "436    0.0\n",
      "861    0.0\n",
      "271    0.0\n",
      "107    0.0\n",
      "72     0.0\n",
      "Name: age, dtype: float64\n",
      "\n",
      "Let's see how column 'occupation' looks like:\n",
      "user_id\n",
      "107    none\n",
      "72     none\n",
      "701    none\n",
      "21     none\n",
      "615    none\n",
      "122    none\n",
      "Name: occupation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We can also pass a dictionary to fillna in order to specify\n",
    "different values to replace NA with.\n",
    "\"\"\"\n",
    "users_fill_na = users_with_na.fillna({'age': 0, 'occupation': 'none'})\n",
    "# Let's verify if changes actually took place!\n",
    "print(\"Let's see how column 'age' looks like:\\n{}\".\n",
    "      format(users_fill_na.loc[row_indices[:6], 'age']))\n",
    "print()\n",
    "print(\"Let's see how column 'occupation' looks like:\\n{}\".\n",
    "      format(users_fill_na.loc[row_indices[4:], 'occupation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows:\n",
      "user_id\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The DataFrame method duplicated() returns a boolean Series \n",
    "indicating whether each row is a duplicate or not.\n",
    "\"\"\"\n",
    "# Let's go back to our original DataFrame\n",
    "print(\"Duplicated rows:\\n{}\".format(users.duplicated().head()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Is there at least one duplicated row? A: True\n"
     ]
    }
   ],
   "source": [
    "# What if I would like to see if there exists at least one duplicated row?\n",
    "print(\"Q: Is there at least one duplicated row? A: {}\"\n",
    "      .format(users.duplicated().any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows:\n",
      "         age gender     occupation zip_code\n",
      "user_id                                    \n",
      "1         24      M     technician    85711\n",
      "2         53      F          other    94043\n",
      "3         23      M         writer    32067\n",
      "4         24      M     technician    43537\n",
      "5         33      F          other    15213\n",
      "...      ...    ...            ...      ...\n",
      "939       26      F        student    33319\n",
      "940       32      M  administrator    02215\n",
      "941       20      M        student    97229\n",
      "942       48      F      librarian    78209\n",
      "943       22      M        student    77841\n",
      "\n",
      "[943 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Suppose I want to extract only the duplicated rows\n",
    "print(\"Duplicated rows:\\n{}\".format(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "5      False\n",
       "       ...  \n",
       "939    False\n",
       "940    False\n",
       "941    False\n",
       "942    False\n",
       "943    False\n",
       "Length: 943, dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows:\n",
      "         age gender occupation zip_code\n",
      "user_id                                \n",
      "496       21      F    student    55414\n",
      "572       51      M   educator    20003\n",
      "621       17      M    student    60402\n",
      "684       28      M    student    55414\n",
      "733       44      F      other    60630\n",
      "805       27      F      other    20009\n",
      "890       32      M    student    97301\n"
     ]
    }
   ],
   "source": [
    "# Suppose I want to extract only the duplicated rows\n",
    "print(\"Duplicated rows:\\n{}\".format(users[users.duplicated()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows:\n",
      "         age gender occupation zip_code\n",
      "user_id                                \n",
      "67        17      M    student    60402\n",
      "85        51      M   educator    20003\n",
      "198       21      F    student    55414\n",
      "350       32      M    student    97301\n",
      "428       28      M    student    55414\n",
      "437       27      F      other    20009\n",
      "460       44      F      other    60630\n",
      "496       21      F    student    55414\n",
      "572       51      M   educator    20003\n",
      "621       17      M    student    60402\n",
      "684       28      M    student    55414\n",
      "733       44      F      other    60630\n",
      "805       27      F      other    20009\n",
      "890       32      M    student    97301\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "By default, if you have 3 duplicated rows, only the last two will be\n",
    "marked as duplicates (i.e., the first occurrence is kept).\n",
    "This can be changed by specifying the parameters 'keep'\n",
    "keep : {'first', 'last', False}, default 'first'\n",
    "first : Mark duplicates as True except for the first occurrence.\n",
    "last : Mark duplicates as True except for the last occurrence.\n",
    "False : Mark all duplicates as True.\n",
    "\"\"\"\n",
    "# Suppose I want to extract only the duplicated rows, this time considering them all\n",
    "print(\"Duplicated rows:\\n{}\".format(users[users.duplicated(keep = False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Is there at least one duplicated row? A: False\n",
      "\n",
      "Total number of rows after removing duplicated rows = 936\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Relatedly, drop_duplicates() returns a DataFrame where the duplicated array is False.\n",
    "\"\"\"\n",
    "# Remove duplicated rows (keeping the first occurrence of each duplicates)\n",
    "users_with_no_dup = users.drop_duplicates()\n",
    "# What if I would like to see if there exists at least one duplicate row, now?\n",
    "print(\"Q: Is there at least one duplicated row? A: {}\"\n",
    "      .format(users_with_no_dup.duplicated().any()))\n",
    "print()\n",
    "print(\"Total number of rows after removing duplicated rows = {}\"\n",
    "      .format(users_with_no_dup.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Is there at least one duplicated row? A: False\n",
      "\n",
      "Total number of rows after removing duplicated rows = 929\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We can also specify the same 'keep' argument to decide on how to\n",
    "mark duplicates, and therefore remove them\n",
    "\"\"\"\n",
    "# Remove ALL duplicated rows\n",
    "users_with_no_dup = users.drop_duplicates(keep = False)\n",
    "# What if I would like to see if there exists at least one duplicate row, now?\n",
    "print(\"Q: Is there at least one duplicated row? A: {}\"\n",
    "      .format(users_with_no_dup.duplicated().any()))\n",
    "print()\n",
    "print(\"Total number of rows after removing duplicated rows = {}\"\n",
    "      .format(users_with_no_dup.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 902 duplicated rows having the same 'gender' and 'occupation'.\n",
      "The following are the first 5 of them:\n",
      "         age gender     occupation zip_code\n",
      "user_id                                    \n",
      "4         24      M     technician    43537\n",
      "5         33      F          other    15213\n",
      "8         36      M  administrator    05201\n",
      "11        39      F          other    30329\n",
      "12        28      F          other    06405\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "By default, both duplicated() and drop_duplicates() consider all of the columns; \n",
    "alternatively we can specify any subset of them to detect duplicates. \n",
    "Suppose we want to filter duplicates only based on the 'gender' and 'occupation' columns.\n",
    "\"\"\"\n",
    "# Suppose I want to extract only the duplicated rows w.r.t. 'gender' and 'occupation'\n",
    "print(\"There are {} duplicated rows having the same 'gender' and 'occupation'.\\n\\\n",
    "The following are the first 5 of them:\\n{}\"\n",
    "      .format(users[users.duplicated(['gender', 'occupation'])].shape[0],\n",
    "              users[users.duplicated(['gender', 'occupation'])].head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transforming Data Using a Function or Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For many data sets, we may wish to perform some transformation based on the values\n",
    "in an array, Series, or column in a DataFrame.\n",
    "\"\"\"\n",
    "# Suppose we want to add a column indicating the salary for each occupation. \n",
    "# Let's write down a mapping of each occupation to salary\n",
    "occupation_to_salary = {'technician': 25000, 'administrator': 150000,\n",
    "                        'writer': 40000, 'executive': 300000, 'other': 18000,\n",
    "                        'student': 1300, 'lawyer': 27500, 'educator': 45000,\n",
    "                        'scientist': 60000, 'entertainment': 185000, 'programmer': 55000,\n",
    "                        'librarian': 22000, 'homemaker': 240000, 'artist': 72000,\n",
    "                        'engineer': 91000, 'marketing': 66000, 'none': 0,\n",
    "                        'healthcare': 41000, 'retired': 52000, 'salesman': 48000,\n",
    "                        'doctor': 140000\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'technician': 25000,\n",
       " 'administrator': 150000,\n",
       " 'writer': 40000,\n",
       " 'executive': 300000,\n",
       " 'other': 18000,\n",
       " 'student': 1300,\n",
       " 'lawyer': 27500,\n",
       " 'educator': 45000,\n",
       " 'scientist': 60000,\n",
       " 'entertainment': 185000,\n",
       " 'programmer': 55000,\n",
       " 'librarian': 22000,\n",
       " 'homemaker': 240000,\n",
       " 'artist': 72000,\n",
       " 'engineer': 91000,\n",
       " 'marketing': 66000,\n",
       " 'none': 0,\n",
       " 'healthcare': 41000,\n",
       " 'retired': 52000,\n",
       " 'salesman': 48000,\n",
       " 'doctor': 140000}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupation_to_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1       25000\n",
       "2       18000\n",
       "3       40000\n",
       "4       25000\n",
       "5       18000\n",
       "        ...  \n",
       "939      1300\n",
       "940    150000\n",
       "941      1300\n",
       "942     22000\n",
       "943      1300\n",
       "Name: occupation, Length: 943, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['occupation'].map(occupation_to_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender  occupation zip_code  salary\n",
      "user_id                                         \n",
      "1         24      M  technician    85711   25000\n",
      "2         53      F       other    94043   18000\n",
      "3         23      M      writer    32067   40000\n",
      "4         24      M  technician    43537   25000\n",
      "5         33      F       other    15213   18000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The map method on a Series accepts a function or dict-like object containing a mapping.\n",
    "\"\"\"\n",
    "users['salary'] = users['occupation'].map(occupation_to_salary)\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender  occupation zip_code\n",
      "user_id                                 \n",
      "1         24      M  technician    85711\n",
      "2         53      F       other    94043\n",
      "3         23      M      writer    32067\n",
      "4         24      M  technician    43537\n",
      "5         33      F       other    15213\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Alternatively, we could also have passed to map a lambda function that does all the work.\n",
    "\"\"\"\n",
    "# Let's first delete the salary column\n",
    "del users['salary']\n",
    "# Verify the column is really removed\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender  occupation zip_code  salary\n",
      "user_id                                         \n",
      "1         24      M  technician    85711   25000\n",
      "2         53      F       other    94043   18000\n",
      "3         23      M      writer    32067   40000\n",
      "4         24      M  technician    43537   25000\n",
      "5         33      F       other    15213   18000\n"
     ]
    }
   ],
   "source": [
    "# lambda function\n",
    "users['salary'] = users['occupation'].map(lambda x: occupation_to_salary[x])\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender  occupation zip_code  salary\n",
      "user_id                                         \n",
      "1         24      M  technician    85711   25000\n",
      "2         53      F       other    94043   18000\n",
      "3         23      M      writer    32067   40000\n",
      "4         24      M  technician    43537   25000\n",
      "5         33      F       other    15213   18000\n"
     ]
    }
   ],
   "source": [
    "# lambda function\n",
    "users['salary'] = users['occupation'].map(lambda o: occupation_to_salary[o])\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Replacing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of replaced rows is = 9\n",
      "The following are the first 5 rows that have been replaced:\n",
      "         age gender occupation zip_code  salary\n",
      "user_id                                        \n",
      "57        16      M        NaN    84010       0\n",
      "127       33      M        NaN    73439       0\n",
      "130       20      M        NaN    60115       0\n",
      "256       35      F        NaN    39042       0\n",
      "289       11      M        NaN    94619       0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Filling in missing data with the 'fillna' method is a special case \n",
    "of more general value replacement. \n",
    "While 'map' can be used to modify a subset of values in an object, \n",
    "'replace' provides a simpler and more flexible way to do so.\n",
    "\"\"\"\n",
    "# Suppose we would like to consider 'none' value of 'occupation' as missing data\n",
    "# (i.e., 'none' can be considered as a sentinel value)\n",
    "# NOTE: remember that this can be also specified when loading the DataFrame\n",
    "# by specifying na_values\n",
    "users['occupation'] = users['occupation'].replace('none', np.nan)\n",
    "print(\"The number of replaced rows is = {}\"\n",
    "      .format(users[(users['occupation'].isnull())].shape[0]))\n",
    "print(\"The following are the first 5 rows that have been replaced:\\n{}\"\n",
    "      .format(users[(users['occupation'].isnull())].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Is there any missing value for 'occupation'? A: True\n"
     ]
    }
   ],
   "source": [
    "# Let's verify that 'occupation' contains actually some NaN\n",
    "print(\"Q: Is there any missing value for 'occupation'? A: {}\".\n",
    "      format(users['occupation'].isnull().any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Suppose I want to update the salary column corresponding to\n",
    "# those rows where 'occupation' is now missing\n",
    "mask = users['occupation'].notnull()\n",
    "# Update 'salary' where 'occupation' is null. The semantics is as follows.\n",
    "# 'salary' will keep its value if the mask condition is verified\n",
    "# (i.e., if 'occupation' is NOT null, otherwise we set it to NaN)\n",
    "users['salary'] = users['salary'].where(mask, np.nan)\n",
    "#np.where(mask, users.salary, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of replaced rows is = 9\n",
      "The following are the first 5 rows that have been replaced:\n",
      "         age gender occupation zip_code  salary\n",
      "user_id                                        \n",
      "57        16      M        NaN    84010     NaN\n",
      "127       33      M        NaN    73439     NaN\n",
      "130       20      M        NaN    60115     NaN\n",
      "256       35      F        NaN    39042     NaN\n",
      "289       11      M        NaN    94619     NaN\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of replaced rows is = {}\"\n",
    "      .format(users[(users['occupation'].isnull()) & (users['salary'].isnull())].shape[0]))\n",
    "print(\"The following are the first 5 rows that have been replaced:\\n{}\"\n",
    "      .format(users[(users['occupation'].isnull()) & (users['salary'].isnull())].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's go back to the original occupation and salary\n",
    "users = users.fillna({'occupation': 'none'})\n",
    "users['salary'] = users['occupation'].map(lambda o: occupation_to_salary[o])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discretization and Binning\n",
    "\n",
    "-  Continuous data is often **discretized** or otherwised separated into \"**bins**\" for analysis. \n",
    "\n",
    "-  The typical example is given by the case where you have user's data containing information like 'age', and you what to divide users in a set of fixed age intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages: user_id\n",
      "1    24\n",
      "2    53\n",
      "3    23\n",
      "4    24\n",
      "5    33\n",
      "Name: age, dtype: int64\n",
      "Categorical ranges: user_id\n",
      "1    [18, 26)\n",
      "2    [36, 56)\n",
      "3    [18, 26)\n",
      "4    [18, 26)\n",
      "5    [26, 36)\n",
      "Name: age, dtype: category\n",
      "Categories (5, interval[int64, left]): [[0, 18) < [18, 26) < [26, 36) < [36, 56) < [56, 100)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's consider our 'age' column and suppose we want to divide these into bins, \n",
    "such as users aged between 0 and 17, 18 to 25, 26 to 35, \n",
    "36 to 55, and finally 56 and older. To do so, we can use pandas.cut function.\n",
    "\"\"\"\n",
    "# Let's first define a list containing the left-most extreme of each bin\n",
    "bins = [0, 18, 26, 36, 56, 100]\n",
    "\"\"\"\n",
    "Consistent with mathematical notation for intervals, a parenthesis ')' \n",
    "means that the side is OPEN while the square bracket '[' means it is closed (inclusive). \n",
    "By default, intervals are left-open, i.e., (a, b]\n",
    "Passing 'right=False' those become right-open, i.e., [a, b) \n",
    "\"\"\"\n",
    "age_intervals = pd.cut(users['age'], bins, right=False)\n",
    "print(\"Ages: {}\".format(users['age'].head()))\n",
    "print(\"Categorical ranges: {}\".format(age_intervals.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical bin codes: user_id\n",
      "1    1\n",
      "2    3\n",
      "3    1\n",
      "4    1\n",
      "5    2\n",
      "dtype: int8\n",
      "Categorical bin names: IntervalIndex([[0, 18), [18, 26), [26, 36), [36, 56), [56, 100)], dtype='interval[int64, left]')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The object pandas returns is a special Categorical object. \n",
    "We can treat it like an array of strings indicating the bin name; \n",
    "internally it contains a categories array indicating the distinct category names \n",
    "along with a labeling for the ages data in the 'codes' attribute\n",
    "\"\"\"\n",
    "print(\"Categorical bin codes: {}\".format(age_intervals.cat.codes.head()))\n",
    "print(\"Categorical bin names: {}\".format(age_intervals.cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages: user_id\n",
      "1    24\n",
      "2    53\n",
      "3    23\n",
      "4    24\n",
      "5    33\n",
      "Name: age, dtype: int64\n",
      "Categorical ranges: user_id\n",
      "1    Young_Adult\n",
      "2    Middle_Aged\n",
      "3    Young_Adult\n",
      "4    Young_Adult\n",
      "5          Adult\n",
      "Name: age, dtype: category\n",
      "Categories (5, object): ['Young' < 'Young_Adult' < 'Adult' < 'Middle_Aged' < 'Senior']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Instead of integer labeling for the bin, we can specify which label\n",
    "to assign to each bin.\n",
    "\"\"\"\n",
    "age_labels = ['Young', 'Young_Adult', 'Adult', 'Middle_Aged', 'Senior']\n",
    "\n",
    "age_intervals = pd.cut(users['age'], bins, labels=age_labels, right=False)\n",
    "\n",
    "print(\"Ages: {}\".format(users['age'].head()))\n",
    "print(\"Categorical ranges: {}\".format(age_intervals.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender  occupation zip_code  salary age_interval\n",
      "user_id                                                      \n",
      "1         24      M  technician    85711   25000  Young_Adult\n",
      "2         53      F       other    94043   18000  Middle_Aged\n",
      "3         23      M      writer    32067   40000  Young_Adult\n",
      "4         24      M  technician    43537   25000  Young_Adult\n",
      "5         33      F       other    15213   18000        Adult\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's create an extra column 'age_interval' on the DataFrame with this information.\n",
    "\"\"\"\n",
    "users['age_interval'] = pd.cut(users['age'], bins, labels=age_labels, right=False)\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages: user_id\n",
      "1    24\n",
      "2    53\n",
      "3    23\n",
      "4    24\n",
      "5    33\n",
      "Name: age, dtype: int64\n",
      "Categorical ranges: user_id\n",
      "1    [20.2, 33.4)\n",
      "2    [46.6, 59.8)\n",
      "3    [20.2, 33.4)\n",
      "4    [20.2, 33.4)\n",
      "5    [20.2, 33.4)\n",
      "Name: age, dtype: category\n",
      "Categories (5, interval[float64, left]): [[7.0, 20.2) < [20.2, 33.4) < [33.4, 46.6) < [46.6, 59.8) < [59.8, 73.066)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sometimes we don't want to specify the intervals ourselves, instead\n",
    "we want to just specify the number of bins and let pandas figure out how \n",
    "data are distributed across those bins.\n",
    "\"\"\"\n",
    "# If we pass 'cut' an integer number of bins instead of explicit bin edges, \n",
    "# it will compute equal-length bins based on the minimum and maximum values in the data. \n",
    "age_intervals = pd.cut(users['age'], 5, right=False)\n",
    "print(\"Ages: {}\".format(users['age'].head()))\n",
    "print(\"Categorical ranges: {}\".format(age_intervals.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages: user_id\n",
      "1    24\n",
      "2    53\n",
      "3    23\n",
      "4    24\n",
      "5    33\n",
      "Name: age, dtype: int64\n",
      "Categorical ranges: user_id\n",
      "1    Young_Adult\n",
      "2    Middle_Aged\n",
      "3    Young_Adult\n",
      "4    Young_Adult\n",
      "5    Young_Adult\n",
      "Name: age, dtype: category\n",
      "Categories (5, object): ['Young' < 'Young_Adult' < 'Adult' < 'Middle_Aged' < 'Senior']\n"
     ]
    }
   ],
   "source": [
    "# The same as above, but with labels\n",
    "age_labels = ['Young', 'Young_Adult', 'Adult', 'Middle_Aged', 'Senior']\n",
    "age_intervals = pd.cut(users['age'], 5, labels=age_labels, right=False)\n",
    "print(\"Ages: {}\".format(users['age'].head()))\n",
    "print(\"Categorical ranges: {}\".format(age_intervals.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages: user_id\n",
      "1    24\n",
      "2    53\n",
      "3    23\n",
      "4    24\n",
      "5    33\n",
      "Name: age, dtype: int64\n",
      "Categorical ranges: user_id\n",
      "1    (6.999, 25.0]\n",
      "2     (43.0, 73.0]\n",
      "3    (6.999, 25.0]\n",
      "4    (6.999, 25.0]\n",
      "5     (31.0, 43.0]\n",
      "Name: age, dtype: category\n",
      "Categories (4, interval[float64, right]): [(6.999, 25.0] < (25.0, 31.0] < (31.0, 43.0] < (43.0, 73.0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A closely related function 'qcut' bins the data based on sample quantiles. \n",
    "Depending on the distribution of the data, using 'cut' will not usually result \n",
    "in each bin having the same number of data points. \n",
    "Instead, with 'qcut' by definition we will obtain roughly equal-size bins.\n",
    "\"\"\"\n",
    "# We are using quartiles here [0.25, 0.50, 0.75, 1]\n",
    "# Alternatively, we can specify the list of our own quantiles \n",
    "# (i.e., numbers between 0 and 1, inclusive)\n",
    "age_intervals = pd.qcut(users['age'], 4)\n",
    "print(\"Ages: {}\".format(users['age'].head()))\n",
    "print(\"Categorical ranges: {}\".format(age_intervals.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ages: user_id\n",
      "1    24\n",
      "2    53\n",
      "3    23\n",
      "4    24\n",
      "5    33\n",
      "Name: age, dtype: int64\n",
      "Categorical ranges: user_id\n",
      "1          Young\n",
      "2         Senior\n",
      "3          Young\n",
      "4          Young\n",
      "5    Middle_Aged\n",
      "Name: age, dtype: category\n",
      "Categories (4, object): ['Young' < 'Adult' < 'Middle_Aged' < 'Senior']\n"
     ]
    }
   ],
   "source": [
    "# The same as above yet with labels\n",
    "age_labels = ['Young', 'Adult', 'Middle_Aged', 'Senior']\n",
    "age_intervals = pd.qcut(users['age'], 4, labels=age_labels)\n",
    "print(\"Ages: {}\".format(users['age'].head()))\n",
    "print(\"Categorical ranges: {}\".format(age_intervals.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Detecting and Filtering Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               age gender occupation zip_code         salary age_interval\n",
      "count   943.000000    943        943      943     943.000000          943\n",
      "unique         NaN      2         21      795            NaN            5\n",
      "top            NaN      M    student    55414            NaN  Middle_Aged\n",
      "freq           NaN    670        196        9            NaN          320\n",
      "mean     34.051962    NaN        NaN      NaN   58394.273595          NaN\n",
      "std      12.192740    NaN        NaN      NaN   66491.286158          NaN\n",
      "min       7.000000    NaN        NaN      NaN       0.000000          NaN\n",
      "25%      25.000000    NaN        NaN      NaN   18000.000000          NaN\n",
      "50%      31.000000    NaN        NaN      NaN   45000.000000          NaN\n",
      "75%      43.000000    NaN        NaN      NaN   72000.000000          NaN\n",
      "max      73.000000    NaN        NaN      NaN  300000.000000          NaN\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's see the output of the 'describe()' function on our DataFrame.\n",
    "\"\"\"\n",
    "print(users.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 salary outliers, 5 of which are as follows:\n",
      "         age gender occupation zip_code  salary age_interval\n",
      "user_id                                                     \n",
      "6         42      M  executive    98101  300000  Middle_Aged\n",
      "54        22      M  executive    66315  300000  Young_Adult\n",
      "84        32      M  executive    55369  300000        Adult\n",
      "93        48      M  executive    23112  300000  Middle_Aged\n",
      "98        49      F  executive    90291  300000  Middle_Aged\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Suppose we want to see what are the records where 'salary' is greater than 280k.\n",
    "\"\"\"\n",
    "salary_outlier = users.salary > 280000\n",
    "print(\"There are {} salary outliers, 5 of which are as follows:\\n{}\"\n",
    "      .format(users[salary_outlier].shape[0], users[salary_outlier].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender occupation zip_code  salary age_interval\n",
      "user_id                                                     \n",
      "6         42      M  executive    98101  280000  Middle_Aged\n",
      "54        22      M  executive    66315  280000  Young_Adult\n",
      "84        32      M  executive    55369  280000        Adult\n",
      "93        48      M  executive    23112  280000  Middle_Aged\n",
      "98        49      F  executive    90291  280000  Middle_Aged\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "If we want to change the value of an outlier with a 'cap' value (e.g., 280000)\n",
    "\"\"\"\n",
    "# 1. Using 'where'\n",
    "users.salary = users.salary.where(~salary_outlier, 280000)\n",
    "print(users[salary_outlier].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender occupation zip_code  salary age_interval\n",
      "user_id                                                     \n",
      "6         42      M  executive    98101  300000  Middle_Aged\n",
      "54        22      M  executive    66315  300000  Young_Adult\n",
      "84        32      M  executive    55369  300000        Adult\n",
      "93        48      M  executive    23112  300000  Middle_Aged\n",
      "98        49      F  executive    90291  300000  Middle_Aged\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Let's revert back to the original salary\n",
    "\"\"\"\n",
    "users.salary = users.salary.where(~salary_outlier, 300000)\n",
    "print(users[salary_outlier].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender occupation zip_code  salary age_interval\n",
      "user_id                                                     \n",
      "6         42      M  executive    98101  280000  Middle_Aged\n",
      "54        22      M  executive    66315  280000  Young_Adult\n",
      "84        32      M  executive    55369  280000        Adult\n",
      "93        48      M  executive    23112  280000  Middle_Aged\n",
      "98        49      F  executive    90291  280000  Middle_Aged\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "If we want to change the value of an outlier with a 'cap' value (e.g., 280000)\n",
    "\"\"\"\n",
    "# 2. Using 'loc'\n",
    "users.loc[salary_outlier, 'salary'] = 280000\n",
    "print(users[salary_outlier].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combining <code>pandas</code> Objects\n",
    "\n",
    "-  Data contained in <code>**pandas**</code> objects (i.e., <code>**Series**</code> and <code>**DataFrame**</code>) can be combined together in a number of built-in ways, such as:\n",
    "\n",
    "    -  <code>**pandas.merge**</code>/<code>**pandas.join**</code> connects rows of two objects based on one or more keys. This is equivalent to **join** operations on relational databases.\n",
    "\n",
    "    -  <code>**pandas.concat**</code> concatenates or \"stacks\" together objects along a specific axis, if any (there is only a single possible axis of concatenation for <code>**Series**</code>).\n",
    "\n",
    "-  Full API documentation is available [here](https://pandas.pydata.org/pandas-docs/stable/merging.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Database-style <code>DataFrame</code> Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender  occupation zip_code\n",
      "user_id                                 \n",
      "1         24      M  technician    85711\n",
      "2         53      F       other    94043\n",
      "3         23      M      writer    32067\n",
      "4         24      M  technician    43537\n",
      "5         33      F       other    15213\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Merge or join operations combine data sets by linking rows using one or more keys. \n",
    "These operations are central to relational databases (e.g., SQL-based). \n",
    "The 'merge' function in pandas is the main entry point for achieving this.\n",
    "\"\"\"\n",
    "# Let's go back to our original DataFrame\n",
    "del users['salary']\n",
    "del users['age_interval']\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a Join/Merge Operation?\n",
    "\n",
    "-  Generally speaking, \"joining\" (\"merging\") two datasets is the process of bringing two datasets together into one, and aligning the rows from each based on common attributes or columns.\n",
    "\n",
    "-  Typical operation in relational databases using <code>**SQL JOIN**</code> operator.\n",
    "\n",
    "-  In <code>**pandas**</code> there are two different functions <code>**merge**</code> and <code>**join**</code>, both of which do similar things; the former is used for column-to-column joins, whereas the latter is more efficient when joining <code>**DataFrame**</code> objects on their indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Anatomy of a Join/Merge Operation\n",
    "\n",
    "```python\n",
    "merged_df = pd.merge(left_df, right_df, \n",
    "                     left_on=[\"l_col_1\",...,\"l_col_n\"], \n",
    "                     right_on=[\"r_col_1\",...,\"r_col_n\"],\n",
    "                     how=\"{left|right|inner|outer}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Anatomy of a Join/Merge Operation\n",
    "\n",
    "-  <code>**left_df**</code> and <code>**right_df**</code> are the two <code>**DataFrame**</code> objects we want to merge.\n",
    "\n",
    "-  <code>**left_on**</code> and <code>**right_on**</code> indicate the column(s) used for the merging operation on the left and right <code>**DataFrame**</code> objects, respectively (alternatively, use just <code>**on=[col_1,...,col_n]**</code> if column names are the same on both <code>**DataFrame**</code>s).\n",
    "\n",
    "-  <code>**how**</code> is used to specify which kind of merge operation needs to be performed, i.e., one of: <code>**left**</code>, <code>**right**</code>, <code>**inner**</code> (default), and <code>**outer**</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Different Types of Join/Merge Operations\n",
    "\n",
    "(./img/join_types.jpg)\n",
    "\n",
    "<center>[Image Source](https://www.shanelynn.ie/merge-join-dataframes-python-pandas-index-1/)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "-  **Inner Merge/Inner Join** (default): Keep only those rows where the value which we want to merge on exists in **both** the **left** and **right** <code>**DataFrame**</code>s.\n",
    "\n",
    "-  **Left Merge/Left (Outer) Join**: Keep every row in the **left** <code>**DataFrame**</code>. If some values of the column we are merging on are missing in the **right** <code>**DataFrame**</code>, add <code>**NaN**</code> to the result.\n",
    "\n",
    "-  **Right Merge/Right (Outer) Join**: Keep every row in the **right** <code>**DataFrame**</code>. If some values of the column we are merging on are missing in the **left** <code>**DataFrame**</code>, add <code>**NaN**</code> to the result.\n",
    "\n",
    "-  **Outer Merge/Full (Outer) Join**: Return **all** the rows from the **left** and the **right** <code>**DataFrame**</code>s, matches up rows where possible, otherwise add <code>**NaN**</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occupation-Salary data:\n",
      "      occupation  salary\n",
      "0  administrator  150000\n",
      "1         writer   40000\n",
      "2      executive  300000\n",
      "3        student    1300\n",
      "4         lawyer   27500\n"
     ]
    }
   ],
   "source": [
    "# Suppose we have another DataFrame containing the (average) salary for some occupations. \n",
    "# Let's assume we don't have salary information for 'technician' and 'other'\n",
    "# but we do for two extra occupations (e.g., 'gardener' and 'professor')\n",
    "occupation_salary_data = {'occupation': ['administrator', 'writer', 'executive', \n",
    "                                       'student', 'lawyer', 'educator', \n",
    "                                       'scientist', 'entertainment', \n",
    "                                       'programmer', 'librarian', 'homemaker', \n",
    "                                       'artist', 'engineer', 'marketing', \n",
    "                                       'none', 'healthcare', 'retired', \n",
    "                                       'salesman', 'doctor', 'gardener', \n",
    "                                       'professor'],\n",
    "        'salary': [150000, 40000, 300000, 1300, 27500, 45000, \n",
    "                      60000, 185000, 55000, 22000, 240000, 72000, \n",
    "                      91000, 66000, 0, 41000, 52000, 48000, \n",
    "                      140000, 16000, 82000]}\n",
    "\n",
    "occupation_salary = pd.DataFrame(occupation_salary_data)\n",
    "print(\"Occupation-Salary data:\\n{}\".format(occupation_salary.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>student</td>\n",
       "      <td>33319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>97229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>librarian</td>\n",
       "      <td>78209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>77841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age gender     occupation zip_code\n",
       "user_id                                    \n",
       "1         24      M     technician    85711\n",
       "2         53      F          other    94043\n",
       "3         23      M         writer    32067\n",
       "4         24      M     technician    43537\n",
       "5         33      F          other    15213\n",
       "...      ...    ...            ...      ...\n",
       "939       26      F        student    33319\n",
       "940       32      M  administrator    02215\n",
       "941       20      M        student    97229\n",
       "942       48      F      librarian    78209\n",
       "943       22      M        student    77841\n",
       "\n",
       "[943 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "By default, 'merge' tries to join DataFrames on the basis of common column names.\n",
    "In our example there is a column called 'occupation', which is common to both DataFrames.\n",
    "Moreover, 'merge' implements an INNER JOIN, which means that the resulting DataFrame \n",
    "will contain all and only those records which match on both the left and right DataFrame. \n",
    "\"\"\"\n",
    "merged = pd.merge(users, occupation_salary)\n",
    "# The above is equivalent to:\n",
    "# merged = users.merge(occupation_salary)\n",
    "# Or:\n",
    "# merged = pd.merge(users, occupation_salary, \n",
    "#                   left_on=\"occupation\", right_on=\"occupation\", how=\"inner\")\n",
    "# Or, again:\n",
    "# merged = pd.merge(users, occupation_salary, on=\"occupation\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>30068</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>40206</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>55369</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>52245</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>doctor</td>\n",
       "      <td>63108</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>doctor</td>\n",
       "      <td>85258</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>doctor</td>\n",
       "      <td>47401</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>64</td>\n",
       "      <td>M</td>\n",
       "      <td>doctor</td>\n",
       "      <td>97405</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>doctor</td>\n",
       "      <td>66221</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>811 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age gender occupation zip_code  salary\n",
       "0     23      M     writer    32067   40000\n",
       "1     26      M     writer    30068   40000\n",
       "2     25      M     writer    40206   40000\n",
       "3     32      M     writer    55369   40000\n",
       "4     21      M     writer    52245   40000\n",
       "..   ...    ...        ...      ...     ...\n",
       "806   29      M     doctor    63108  140000\n",
       "807   51      M     doctor    85258  140000\n",
       "808   45      M     doctor    47401  140000\n",
       "809   64      M     doctor    97405  140000\n",
       "810   42      M     doctor    66221  140000\n",
       "\n",
       "[811 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the left DataFrame: 943\n",
      "Number of records in the right DataFrame: 21\n",
      "Unique values of 'occupation' in the left DataFrame:\n",
      "['technician' 'other' 'writer' 'executive' 'administrator' 'student'\n",
      " 'lawyer' 'educator' 'scientist' 'entertainment' 'programmer' 'librarian'\n",
      " 'homemaker' 'artist' 'engineer' 'marketing' 'none' 'healthcare' 'retired'\n",
      " 'salesman' 'doctor']\n",
      "Unique values of 'occupation' in the right DataFrame:\n",
      "['administrator' 'writer' 'executive' 'student' 'lawyer' 'educator'\n",
      " 'scientist' 'entertainment' 'programmer' 'librarian' 'homemaker' 'artist'\n",
      " 'engineer' 'marketing' 'none' 'healthcare' 'retired' 'salesman' 'doctor'\n",
      " 'gardener' 'professor']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in the left DataFrame: {}\"\n",
    "      .format(users.shape[0]))\n",
    "print(\"Number of records in the right DataFrame: {}\"\n",
    "      .format(occupation_salary.shape[0]))\n",
    "print(\"Unique values of 'occupation' in the left DataFrame:\\n{}\".\n",
    "      format(users.occupation.unique()))\n",
    "print(\"Unique values of 'occupation' in the right DataFrame:\\n{}\".\n",
    "      format(occupation_salary.occupation.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in the resulting merged DataFrame: 811\n",
      "   age gender occupation zip_code  salary\n",
      "0   23      M     writer    32067   40000\n",
      "1   26      M     writer    30068   40000\n",
      "2   25      M     writer    40206   40000\n",
      "3   32      M     writer    55369   40000\n",
      "4   21      M     writer    52245   40000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in the resulting merged DataFrame: {}\"\n",
    "      .format(merged.shape[0]))\n",
    "print(merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'occupation' values shared between the two DataFrames:\n",
      "True     811\n",
      "False    132\n",
      "Name: occupation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Double check if the number of resulting rows after (inner) merge is compliant with\n",
    "what we expect. Remember, inner merge results in a number of records which correspond\n",
    "to the intersection of values on which we merge the 2 DataFrames on.\n",
    "\"\"\"\n",
    "# Let's see how many occupation values in the left DataFrame (users) \n",
    "# appear also in the right DataFrame (occupation_salary)\n",
    "print(\"Number of 'occupation' values shared between the two DataFrames:\\n{}\"\n",
    "      .format(users.occupation.isin(occupation_salary.occupation).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age gender  occupation zip_code   salary\n",
      "0   24      M  technician    85711      NaN\n",
      "1   53      F       other    94043      NaN\n",
      "2   23      M      writer    32067  40000.0\n",
      "3   24      M  technician    43537      NaN\n",
      "4   33      F       other    15213      NaN\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Suppose we want to keep the records from the left DataFrame\n",
    "\"\"\"\n",
    "merged_left = pd.merge(users, occupation_salary, how='left')\n",
    "print(merged_left.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number of records: 943\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "How many records do we expect the resulting merged DataFrame above to have?\n",
    "\"\"\"\n",
    "print(\"Actual number of records: {}\".format(merged_left.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age gender     occupation zip_code  salary\n",
      "0  57.0      M  administrator    91344  150000\n",
      "1  36.0      M  administrator    05201  150000\n",
      "2  38.0      F  administrator    42141  150000\n",
      "3  30.0      M  administrator    17870  150000\n",
      "4  45.0      M  administrator    12550  150000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Suppose we want to keep the records from the right DataFrame\n",
    "\"\"\"\n",
    "merged_right = pd.merge(users, occupation_salary, how='right')\n",
    "print(merged_right.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number of records: 813\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "How many records do we expect the resulting merged DataFrame above to have?\n",
    "\"\"\"\n",
    "print(\"Actual number of records: {}\".format(merged_right.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender occupation zip_code  salary\n",
      "user_id                                        \n",
      "3         23      M     writer    32067   40000\n",
      "6         26      M     writer    30068   40000\n",
      "7         25      M     writer    40206   40000\n",
      "8         32      M     writer    55369   40000\n",
      "9         21      M     writer    52245   40000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "When we use 'merge' on column(s)-to-column(s) \n",
    "the indexes associated with the merging DataFrame objects are discarded.\n",
    "\"\"\"\n",
    "# Suppose we want to re-assign an Index object to the new merged DataFrame\n",
    "# using the previous non-default index of the left DataFrame (users)\n",
    "merged.index.name = 'user_id'\n",
    "\n",
    "merged.index = users.index[users.occupation.isin(occupation_salary.occupation)]\n",
    "print(merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected number of random users = 100\n",
      "Q: Is there any duplicates? A: False\n"
     ]
    }
   ],
   "source": [
    "# Suppose we want to create another DataFrame containing the (average) salary\n",
    "# for a set of 100 random users (i.e., not occupations)\n",
    "# 1. Let's pick 100 user_ids uniformly at random\n",
    "np.random.seed(23)\n",
    "\n",
    "random_users = np.random.choice(users.index, 100, replace=False)\n",
    "\n",
    "print(\"Selected number of random users = {}\"\n",
    "      .format(random_users.size))\n",
    "\n",
    "print(\"Q: Is there any duplicates? A: {}\"\n",
    "      .format(pd.Series(random_users).duplicated().any()))\n",
    "\n",
    "# print(\"Q: Is there any duplicates? A: {}\"\n",
    "#       .format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38998.   31536.25 24355.11 30103.51 35611.84 17615.86 30250.3  42118.84\n",
      " 45847.16 29421.92 39273.15 15920.3  36359.8  30626.69 48296.49 49052.06\n",
      " 37141.21 14254.57 17026.05 22536.88 31362.75 33050.27 28228.48 28927.89\n",
      " 23757.09 12374.72 36929.46 52598.52 33504.45 24091.63 34289.28 27012.23\n",
      " 49070.25 48796.16 50157.58 24038.21 23184.02 29043.14 29916.06 35666.19\n",
      " 38366.95 47605.43 40696.15 48960.02 25552.93 18293.37 46354.33 32787.86\n",
      " 20396.14 48080.51 44002.58  3036.52 36445.56 20929.12 20650.53 31487.91\n",
      " 28289.03 46646.2  35364.38 40477.7  27323.17 38161.09 30423.14 34731.28\n",
      " 33913.6  38928.43 51416.31 49240.69 24231.9  35424.29 27401.46 42575.65\n",
      " 47567.94 39560.88 46178.75 20353.03 43897.89 55995.4  57611.83 31803.22\n",
      " 20234.6  35326.04 21825.77 46465.83 41483.11 40326.54 39110.58 42819.58\n",
      " 30729.51 29656.11 29773.18 30663.94 28703.19 26390.94 58986.96 24663.34\n",
      " 45841.04 32877.53 35263.56 29464.62]\n"
     ]
    }
   ],
   "source": [
    "# 2. Let's do the same with the average salary.\n",
    "# This time we extract a 100-sample drawn from a Normal distribution.\n",
    "# To do so, we need to specify the two parameters of the distribution: \n",
    "# mean (mu) and standard deviation (sigma)\n",
    "mu = 35000\n",
    "sigma = 10000\n",
    "normal_salaries = np.random.normal(mu, sigma, 100)\n",
    "\n",
    "# Let's also round salaries to the 2nd decimal digit\n",
    "normal_salaries = np.round(normal_salaries, decimals=2)\n",
    "print(normal_salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Let's do the same with the average salary.\n",
    "# This time we extract a 100-sample drawn from a Normal distribution.\n",
    "# To do so, we need to specify the two parameters of the distribution: \n",
    "# mean (mu) and standard deviation (sigma)\n",
    "mu = 35000\n",
    "sigma = 10000\n",
    "normal_salaries = np.random.normal(loc=mu, scale=sigma, size=100)\n",
    "# Let's also round salaries to the 2nd decimal digit\n",
    "normal_salaries = np.round(normal_salaries, decimals=2)\n",
    "# Alternatively:\n",
    "# np.round(normal_salaries, decimals=2, out=normal_salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Salary data:\n",
      "           salary\n",
      "user_id          \n",
      "640      29778.94\n",
      "320      35025.35\n",
      "877      40907.00\n",
      "772      41766.32\n",
      "316      43400.22\n"
     ]
    }
   ],
   "source": [
    "# 3. Let's now create the dictionary containing two keys: 'user_id' and 'salary'\n",
    "# For each key, we associate the list of random_users and normal_salaries, respectively\n",
    "user_to_salary_data = {'user_id': random_users, 'salary': normal_salaries}\n",
    "\n",
    "# 4. We create the corresponding pandas DataFrame object\n",
    "user_to_salary = pd.DataFrame(user_to_salary_data)\n",
    "\n",
    "user_to_salary.set_index('user_id', inplace=True)\n",
    "\n",
    "print(\"User-Salary data:\\n{}\".format(user_to_salary.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender occupation zip_code    salary\n",
      "user_id                                          \n",
      "22        25      M     writer    40206  43972.37\n",
      "25        39      M   engineer    55107  27868.12\n",
      "30         7      M    student    55436  28235.88\n",
      "54        22      M  executive    66315  39189.23\n",
      "64        32      M   educator    43202  38699.79\n"
     ]
    }
   ],
   "source": [
    "# 5. Finally, merge (join) the original DataFrame (users) with this new one\n",
    "# Merging uses the index this time, rather than the column as before\n",
    "merged = pd.merge(users, user_to_salary, left_index=True, right_index=True)\n",
    "\n",
    "# Note that if you don't specify that you are merging on indexes, \n",
    "# merge raises an error!\n",
    "print(merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender occupation zip_code    salary\n",
      "user_id                                          \n",
      "22        25      M     writer    40206  43972.37\n",
      "25        39      M   engineer    55107  27868.12\n",
      "30         7      M    student    55436  28235.88\n",
      "54        22      M  executive    66315  39189.23\n",
      "64        32      M   educator    43202  38699.79\n"
     ]
    }
   ],
   "source": [
    "# 5. Finally, merge (join) the original DataFrame (users) with this new one\n",
    "# Merging uses the index this time, rather than the column as before\n",
    "#merged = pd.merge(users, user_to_salary, left_index=True, right_index=True)\n",
    "# Note that if you don't specify that you are merging on indexes, \n",
    "# merge raises an error!\n",
    "# This is equivalent to (join is 'left' by default):\n",
    "\n",
    "merged = users.join(user_to_salary, how='inner')\n",
    "\n",
    "print(merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <code>pandas.merge</code> Arguments (1 of 2)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./img/pd_merge_args_1.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <code>pandas.merge</code> Arguments (1 of 2)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./img/pd_merge_args_2.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Options for the <code>how</code> Argument\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./img/pd_merge_how.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concatenating <code>DataFrame</code>s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records of 'users':\n",
      "         age gender  occupation zip_code\n",
      "user_id                                 \n",
      "1         24      M  technician    85711\n",
      "2         53      F       other    94043\n",
      "3         23      M      writer    32067\n",
      "4         24      M  technician    43537\n",
      "5         33      F       other    15213\n",
      "\n",
      "Last 5 records of 'users':\n",
      "         age gender     occupation zip_code\n",
      "user_id                                    \n",
      "939       26      F        student    33319\n",
      "940       32      M  administrator    02215\n",
      "941       20      M        student    97229\n",
      "942       48      F      librarian    78209\n",
      "943       22      M        student    77841\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We can use the 'concat' function in pandas to append either rows or columns (if any) \n",
    "from one object to another. \n",
    "Let's grab two subsets of our DataFrame to see how this works.\n",
    "\"\"\"\n",
    "# Read in first 5 rows of users table\n",
    "users_first_5 = users.head()\n",
    "print(\"First 5 records of 'users':\\n{}\".format(users_first_5))\n",
    "print()\n",
    "# Read in the last 5 rows\n",
    "users_last_5 = users[-5:]\n",
    "print(\"Last 5 records of 'users':\\n{}\".format(users_last_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 records of 'users':\n",
      "         age gender  occupation zip_code\n",
      "user_id                                 \n",
      "1         24      M  technician    85711\n",
      "2         53      F       other    94043\n",
      "3         23      M      writer    32067\n",
      "4         24      M  technician    43537\n",
      "5         33      F       other    15213\n",
      "\n",
      "Last 5 records of 'users':\n",
      "         age gender     occupation zip_code\n",
      "user_id                                    \n",
      "939       26      F        student    33319\n",
      "940       32      M  administrator    02215\n",
      "941       20      M        student    97229\n",
      "942       48      F      librarian    78209\n",
      "943       22      M        student    77841\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We can use the 'concat' function in pandas to append either rows or columns (if any) \n",
    "from one object to another. \n",
    "Let's grab two subsets of our DataFrame to see how this works.\n",
    "\"\"\"\n",
    "# Read in first 5 rows of users table\n",
    "users_first_5 = users.head()\n",
    "print(\"First 5 records of 'users':\\n{}\".format(users_first_5))\n",
    "print()\n",
    "# Read in the last 5 rows\n",
    "users_last_5 = users[-5:]\n",
    "print(\"Last 5 records of 'users':\\n{}\".format(users_last_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stack \"_vertically_\" vs. \"_horizontally_\": <code>axis</code>\n",
    "\n",
    "-  By default, <code>**concat**</code> operates on <code>**axis=0**</code> (i.e., **rows**) and tells <code>**pandas**</code> to stack the second DataFrame under the first one (i.e., **vertically**). \n",
    "    -  In order for this to work, we need to make sure that both <code>**DataFrame**</code>s have the same column names and formats. \n",
    "\n",
    "-  Instead, <code>**axis=1**</code> will stack the **columns** in the second <code>**DataFrame**</code> to the right of the first one (i.e., **horizontally**). \n",
    "    - In this case, we want to make sure that the data we stack are related in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender     occupation zip_code\n",
      "user_id                                    \n",
      "1         24      M     technician    85711\n",
      "2         53      F          other    94043\n",
      "3         23      M         writer    32067\n",
      "4         24      M     technician    43537\n",
      "5         33      F          other    15213\n",
      "939       26      F        student    33319\n",
      "940       32      M  administrator    02215\n",
      "941       20      M        student    97229\n",
      "942       48      F      librarian    78209\n",
      "943       22      M        student    77841\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Stack DataFrames vertically (i.e., using default axis=0)\n",
    "\"\"\"\n",
    "# Stack the two DataFrames 'users_first_5' and 'users_last_5' on top of each other\n",
    "vertical_stack = pd.concat([users_first_5, users_last_5], axis=0)\n",
    "print(vertical_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age gender  occupation zip_code   age gender     occupation zip_code\n",
      "user_id                                                                       \n",
      "1        24.0      M  technician    85711   NaN    NaN            NaN      NaN\n",
      "2        53.0      F       other    94043   NaN    NaN            NaN      NaN\n",
      "3        23.0      M      writer    32067   NaN    NaN            NaN      NaN\n",
      "4        24.0      M  technician    43537   NaN    NaN            NaN      NaN\n",
      "5        33.0      F       other    15213   NaN    NaN            NaN      NaN\n",
      "939       NaN    NaN         NaN      NaN  26.0      F        student    33319\n",
      "940       NaN    NaN         NaN      NaN  32.0      M  administrator    02215\n",
      "941       NaN    NaN         NaN      NaN  20.0      M        student    97229\n",
      "942       NaN    NaN         NaN      NaN  48.0      F      librarian    78209\n",
      "943       NaN    NaN         NaN      NaN  22.0      M        student    77841\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Stack DataFrames horizontally (i.e., using axis=1)\n",
    "\"\"\"\n",
    "# Place the two DataFrames 'users_first_5' and 'users_last_5' side by side\n",
    "horizontal_stack = pd.concat([users_first_5, users_last_5], axis=1)\n",
    "print(horizontal_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender  occupation zip_code  age gender     occupation zip_code\n",
      "user_id                                                                     \n",
      "1         24      M  technician    85711   26      F        student    33319\n",
      "2         53      F       other    94043   32      M  administrator    02215\n",
      "3         23      M      writer    32067   20      M        student    97229\n",
      "4         24      M  technician    43537   48      F      librarian    78209\n",
      "5         33      F       other    15213   22      M        student    77841\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Since the row indexes for the two DataFrames 'users_first_5' and 'users_last_5' \n",
    "are not the same, 'concat' can't place them next to each other (NaN values occur). \n",
    "A workaround for this is to reindex our second DataFrame using the 'reset_index()' method.\n",
    "\"\"\"\n",
    "# Set the index of the second DataFrame to that of the first one\n",
    "users_last_5.set_index(users_first_5.index, inplace=True)\n",
    "horizontal_stack = pd.concat([users_first_5, users_last_5], axis=1)\n",
    "print(horizontal_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         age gender  occupation zip_code  age gender     occupation zip_code\n",
      "user_id                                                                     \n",
      "1         24      M  technician    85711   26      F        student    33319\n",
      "2         53      F       other    94043   32      M  administrator    02215\n",
      "3         23      M      writer    32067   20      M        student    97229\n",
      "4         24      M  technician    43537   48      F      librarian    78209\n",
      "5         33      F       other    15213   22      M        student    77841\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Since the row indexes for the two DataFrames 'users_first_5' and 'users_last_5' \n",
    "are not the same, 'concat' can't place them next to each other (NaN values occur). \n",
    "A workaround for this is to reindex our second DataFrame using the 'reset_index()' method.\n",
    "\"\"\"\n",
    "# Set the index of the second DataFrame to that of the first one\n",
    "users_last_5.set_index(users_first_5.index, inplace=True)\n",
    "# Or:\n",
    "# users_last_5 = users_last_5.set_index(users_first_5.index)\n",
    "horizontal_stack = pd.concat([users_first_5, users_last_5], axis=1)\n",
    "print(horizontal_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  age\n",
       "user_id          \n",
       "1         24   26\n",
       "2         53   32\n",
       "3         23   20\n",
       "4         24   48\n",
       "5         33   22"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizontal_stack['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <code>pandas.concat</code> Arguments\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./img/pd_concat.png\">\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
